{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204c0add",
   "metadata": {},
   "source": [
    "# Evaluating `TfidfLogisticRegression` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b4167b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from text_classification import defs\n",
    "from text_classification.data import Samples\n",
    "from text_classification.models import TfidfLogisticRegression\n",
    "from text_classification.metrics import report_from_base64\n",
    "from text_classification.transforms import extract_label, LabelTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57b2704",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "            A: Art       0.79      0.40      1.00      0.53      0.63      0.37       424\n",
      "    B: Environment       0.74      0.50      0.99      0.60      0.71      0.48       407\n",
      "          C: Crime       0.65      0.44      0.99      0.52      0.66      0.41       405\n",
      "      D: Diversity       0.74      0.72      0.95      0.73      0.83      0.67      2009\n",
      "   E: Relationship       0.91      0.80      0.99      0.85      0.89      0.78       995\n",
      "        F: Fashion       0.83      0.89      0.97      0.86      0.93      0.86      2014\n",
      "    G: US Politics       0.80      0.92      0.90      0.85      0.91      0.82      4021\n",
      "H: Foreign Affairs       0.72      0.36      1.00      0.48      0.60      0.33       416\n",
      "        I: Bizarre       0.63      0.37      0.99      0.46      0.60      0.34       378\n",
      "      J: Parenting       0.78      0.89      0.96      0.83      0.92      0.85      1931\n",
      "\n",
      "       avg / total       0.79      0.79      0.95      0.78      0.86      0.74     13000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# todo: find a way to retrieve dagster asset metadata programatically, instead of via copying!\n",
    "\n",
    "f1_train = \"0.788\"\n",
    "f1_valid = \"0.672\"\n",
    "\n",
    "valid_report_base64 = \"ICAgICAgICAgICAgICAgICAgICAgICAgICBwcmUgICAgICAgcmVjICAgICAgIHNwZSAgICAgICAgZjEgICAgICAgZ2VvICAgICAgIGliYSAgICAgICBzdXAKCiAgICAgICAgICAgIEE6IEFydCAgICAgICAwLjc5ICAgICAgMC40MCAgICAgIDEuMDAgICAgICAwLjUzICAgICAgMC42MyAgICAgIDAuMzcgICAgICAgNDI0CiAgICBCOiBFbnZpcm9ubWVudCAgICAgICAwLjc0ICAgICAgMC41MCAgICAgIDAuOTkgICAgICAwLjYwICAgICAgMC43MSAgICAgIDAuNDggICAgICAgNDA3CiAgICAgICAgICBDOiBDcmltZSAgICAgICAwLjY1ICAgICAgMC40NCAgICAgIDAuOTkgICAgICAwLjUyICAgICAgMC42NiAgICAgIDAuNDEgICAgICAgNDA1CiAgICAgIEQ6IERpdmVyc2l0eSAgICAgICAwLjc0ICAgICAgMC43MiAgICAgIDAuOTUgICAgICAwLjczICAgICAgMC44MyAgICAgIDAuNjcgICAgICAyMDA5CiAgIEU6IFJlbGF0aW9uc2hpcCAgICAgICAwLjkxICAgICAgMC44MCAgICAgIDAuOTkgICAgICAwLjg1ICAgICAgMC44OSAgICAgIDAuNzggICAgICAgOTk1CiAgICAgICAgRjogRmFzaGlvbiAgICAgICAwLjgzICAgICAgMC44OSAgICAgIDAuOTcgICAgICAwLjg2ICAgICAgMC45MyAgICAgIDAuODYgICAgICAyMDE0CiAgICBHOiBVUyBQb2xpdGljcyAgICAgICAwLjgwICAgICAgMC45MiAgICAgIDAuOTAgICAgICAwLjg1ICAgICAgMC45MSAgICAgIDAuODIgICAgICA0MDIxCkg6IEZvcmVpZ24gQWZmYWlycyAgICAgICAwLjcyICAgICAgMC4zNiAgICAgIDEuMDAgICAgICAwLjQ4ICAgICAgMC42MCAgICAgIDAuMzMgICAgICAgNDE2CiAgICAgICAgSTogQml6YXJyZSAgICAgICAwLjYzICAgICAgMC4zNyAgICAgIDAuOTkgICAgICAwLjQ2ICAgICAgMC42MCAgICAgIDAuMzQgICAgICAgMzc4CiAgICAgIEo6IFBhcmVudGluZyAgICAgICAwLjc4ICAgICAgMC44OSAgICAgIDAuOTYgICAgICAwLjgzICAgICAgMC45MiAgICAgIDAuODUgICAgICAxOTMxCgogICAgICAgYXZnIC8gdG90YWwgICAgICAgMC43OSAgICAgIDAuNzkgICAgICAwLjk1ICAgICAgMC43OCAgICAgIDAuODYgICAgICAwLjc0ICAgICAxMzAwMAo=\"\n",
    "valid_report = report_from_base64(valid_report_base64)\n",
    "print(valid_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2156df",
   "metadata": {},
   "source": [
    "* Best Precision: \"E: Relationship\" 91%\n",
    "* Worst Precision: \"I: Bizarre\" 63%\n",
    "\n",
    "* Best Recall: \"G: US Politics\" 92%\n",
    "* Worst Recall: \"H: Foreign Affairs\" 36%\n",
    "    \n",
    "üß† Quite different performance between categories, that's hidden by a (macro) averaged F1 Score.\n",
    "\n",
    "‚ùì Is performance correlated to number of samples per category?\n",
    "\n",
    "üß† Yes, majority class in training set is \"G: US Politics\". And \"I: Bizarre\" is a minority classes.\n",
    "\n",
    "üí° Could try balancing the classes.\n",
    "\n",
    "üí™ Add undersampling (as simplest approach) and retest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409e55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "            A: Art       0.39      0.70      0.96      0.50      0.82      0.66       424\n",
      "    B: Environment       0.48      0.75      0.97      0.58      0.85      0.71       407\n",
      "          C: Crime       0.42      0.73      0.97      0.54      0.84      0.69       405\n",
      "      D: Diversity       0.77      0.58      0.97      0.66      0.75      0.54      2009\n",
      "   E: Relationship       0.85      0.82      0.99      0.84      0.90      0.80       995\n",
      "        F: Fashion       0.88      0.81      0.98      0.84      0.89      0.78      2014\n",
      "    G: US Politics       0.92      0.71      0.97      0.80      0.83      0.67      4021\n",
      "H: Foreign Affairs       0.40      0.74      0.96      0.52      0.84      0.70       416\n",
      "        I: Bizarre       0.32      0.63      0.96      0.42      0.78      0.59       378\n",
      "      J: Parenting       0.81      0.81      0.97      0.81      0.89      0.77      1931\n",
      "\n",
      "       avg / total       0.79      0.73      0.97      0.75      0.84      0.69     13000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after undersampling\n",
    "\n",
    "f1_train = \"0.883\"\n",
    "f1_valid = \"0.652\"\n",
    "\n",
    "valid_report_base64 = \"ICAgICAgICAgICAgICAgICAgICAgICAgICBwcmUgICAgICAgcmVjICAgICAgIHNwZSAgICAgICAgZjEgICAgICAgZ2VvICAgICAgIGliYSAgICAgICBzdXAKCiAgICAgICAgICAgIEE6IEFydCAgICAgICAwLjM5ICAgICAgMC43MCAgICAgIDAuOTYgICAgICAwLjUwICAgICAgMC44MiAgICAgIDAuNjYgICAgICAgNDI0CiAgICBCOiBFbnZpcm9ubWVudCAgICAgICAwLjQ4ICAgICAgMC43NSAgICAgIDAuOTcgICAgICAwLjU4ICAgICAgMC44NSAgICAgIDAuNzEgICAgICAgNDA3CiAgICAgICAgICBDOiBDcmltZSAgICAgICAwLjQyICAgICAgMC43MyAgICAgIDAuOTcgICAgICAwLjU0ICAgICAgMC44NCAgICAgIDAuNjkgICAgICAgNDA1CiAgICAgIEQ6IERpdmVyc2l0eSAgICAgICAwLjc3ICAgICAgMC41OCAgICAgIDAuOTcgICAgICAwLjY2ICAgICAgMC43NSAgICAgIDAuNTQgICAgICAyMDA5CiAgIEU6IFJlbGF0aW9uc2hpcCAgICAgICAwLjg1ICAgICAgMC44MiAgICAgIDAuOTkgICAgICAwLjg0ICAgICAgMC45MCAgICAgIDAuODAgICAgICAgOTk1CiAgICAgICAgRjogRmFzaGlvbiAgICAgICAwLjg4ICAgICAgMC44MSAgICAgIDAuOTggICAgICAwLjg0ICAgICAgMC44OSAgICAgIDAuNzggICAgICAyMDE0CiAgICBHOiBVUyBQb2xpdGljcyAgICAgICAwLjkyICAgICAgMC43MSAgICAgIDAuOTcgICAgICAwLjgwICAgICAgMC44MyAgICAgIDAuNjcgICAgICA0MDIxCkg6IEZvcmVpZ24gQWZmYWlycyAgICAgICAwLjQwICAgICAgMC43NCAgICAgIDAuOTYgICAgICAwLjUyICAgICAgMC44NCAgICAgIDAuNzAgICAgICAgNDE2CiAgICAgICAgSTogQml6YXJyZSAgICAgICAwLjMyICAgICAgMC42MyAgICAgIDAuOTYgICAgICAwLjQyICAgICAgMC43OCAgICAgIDAuNTkgICAgICAgMzc4CiAgICAgIEo6IFBhcmVudGluZyAgICAgICAwLjgxICAgICAgMC44MSAgICAgIDAuOTcgICAgICAwLjgxICAgICAgMC44OSAgICAgIDAuNzcgICAgICAxOTMxCgogICAgICAgYXZnIC8gdG90YWwgICAgICAgMC43OSAgICAgIDAuNzMgICAgICAwLjk3ICAgICAgMC43NSAgICAgIDAuODQgICAgICAwLjY5ICAgICAxMzAwMAo=\"\n",
    "valid_report = report_from_base64(valid_report_base64)\n",
    "print(valid_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3daa474",
   "metadata": {},
   "source": [
    "üëé Worse validation metrics after undersampling\n",
    "\n",
    "üß† Minority classes have better recall, but worse precision.\n",
    "\n",
    "üß† Most likely due to incorrect `LogisticRegression` intercepts.\n",
    "\n",
    "üß† Will revert to using the original unbalanced training dataset.\n",
    "\n",
    "‚ùì What are some examples that the model gets wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ae470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 23:33:12 +0000 - dagster - DEBUG - system - Loading file from: /Users/thomelane/Projects/text_classification/data/storage/tfidf_logistic_regression_model\n",
      "2023-02-12 23:33:12 +0000 - dagster - DEBUG - system - Loading file from: /Users/thomelane/Projects/text_classification/data/storage/validation_set\n",
      "2023-02-12 23:33:12 +0000 - dagster - DEBUG - system - Loading file from: /Users/thomelane/Projects/text_classification/data/storage/label_transform\n"
     ]
    }
   ],
   "source": [
    "model: TfidfLogisticRegression = defs.load_asset_value(\"tfidf_logistic_regression_model\")  # type: ignore\n",
    "validation_set: Samples = defs.load_asset_value(\"validation_set\")  # type: ignore\n",
    "label_transform: LabelTransform = defs.load_asset_value(\"label_transform\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8011c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_label(validation_set, label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24d0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be527f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of the samples that were misclassified\n",
    "misclassified_idxs = np.where(y != y_pred)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0dc669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"headline\": \"ProFlowers Receives Barrage Of Twitter Complaints Following Bad Mother's Day Bouquets (PHOTO)\",\n",
      "    \"short_description\": \"This is the second time they've dropped the ball during a major holiday this year.\",\n",
      "    \"id\": 23495,\n",
      "    \"label_true\": \"F: Fashion\",\n",
      "    \"label_pred\": \"J: Parenting\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Mom Wants Justice For Boy Who Killed Himself After Social Media Hoax\",\n",
      "    \"short_description\": \"Tyson Benz's mother says a 13-year-old girl charged in connection with her son's death is not facing a harsh enough punishment.\",\n",
      "    \"id\": 5901,\n",
      "    \"label_true\": \"C: Crime\",\n",
      "    \"label_pred\": \"J: Parenting\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Texas Adoption Bill Could Allow Anti-Gay, Religious Discrimination\",\n",
      "    \"short_description\": \"Critics of the bill say it legitimizes discrimination with taxpayer money.\",\n",
      "    \"id\": 41233,\n",
      "    \"label_true\": \"G: US Politics\",\n",
      "    \"label_pred\": \"D: Diversity\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"What the Paris Attack Is Really About (Hint -- Neither Free Speech Nor the Varied Nature of Muslims)\",\n",
      "    \"short_description\": \"Both of these large points are true in general, perhaps to the point of banality. Yet the first is too general and the second too specific. Both conceal real nuances that are important to moving policy discussions forward.\",\n",
      "    \"id\": 51020,\n",
      "    \"label_true\": \"H: Foreign Affairs\",\n",
      "    \"label_pred\": \"G: US Politics\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Powerful Earthquake Rocks Underwater Divers In The Philippines\",\n",
      "    \"short_description\": \"\\u201cIt felt like there was a huge propeller of a big boat turning around directly above us,\\u201d one diver said.\",\n",
      "    \"id\": 3718,\n",
      "    \"label_true\": \"B: Environment\",\n",
      "    \"label_pred\": \"H: Foreign Affairs\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Mom Of Boy Who Brought Gun To Class Hears her Fate\",\n",
      "    \"short_description\": \"\",\n",
      "    \"id\": 4998,\n",
      "    \"label_true\": \"C: Crime\",\n",
      "    \"label_pred\": \"J: Parenting\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Sewage Truck Carrying Porta-Potties Rolls Over, Dumps Stinky Mess\",\n",
      "    \"short_description\": \"The vehicle reportedly swerved to avoid a barrel while driving near Mesa, Arizona.\",\n",
      "    \"id\": 53379,\n",
      "    \"label_true\": \"I: Bizarre\",\n",
      "    \"label_pred\": \"G: US Politics\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"Michigan Congressman Calls For Police Reforms After Cop Who Killed 7-Year-Old Walks\",\n",
      "    \"short_description\": \"\",\n",
      "    \"id\": 14999,\n",
      "    \"label_true\": \"D: Diversity\",\n",
      "    \"label_pred\": \"G: US Politics\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"2018 Swedish Music Festival Cancelled After Sexual Assault Reports At This Year's Event\",\n",
      "    \"short_description\": \"Multiple cases of sexual violence -- including rape -- reported at Bravalla Festival for second year in a row.\",\n",
      "    \"id\": 51413,\n",
      "    \"label_true\": \"H: Foreign Affairs\",\n",
      "    \"label_pred\": \"C: Crime\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"headline\": \"After Bomb Threats And Backlash, BBQ Restaurant Stands Firm On 'White Appreciation Day'\",\n",
      "    \"short_description\": \"\",\n",
      "    \"id\": 53145,\n",
      "    \"label_true\": \"I: Bizarre\",\n",
      "    \"label_pred\": \"G: US Politics\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in misclassified_idxs[10:20]:\n",
    "    sample = X[i].copy()\n",
    "    sample[\"label_true\"] = label_transform.idx_to_label(y[i])\n",
    "    sample[\"label_pred\"] = label_transform.idx_to_label(y_pred[i])\n",
    "    print(json.dumps(sample, indent=4) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4950d67",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"headline\": \"Cupid's Arrow\",\n",
    "    \"short_description\": \"I remember, as a child, desperately wishing Cupid would hit me with his arrow so I'd fall instantly in love and live happily ever after. Cupid let me down.\",\n",
    "    \"id\": 16179,\n",
    "    \"label_true\": \"E: Relationship\",\n",
    "    \"label_pred\": \"J: Parenting\"\n",
    "}\n",
    "```\n",
    "\n",
    "üß† Can see how a bag-of-words approach could get confused here.\n",
    "\n",
    "üß† Contains the word \"child\" which was a highly weighted for the \"J: Parenting\" class.\n",
    "\n",
    "üß† \"Cupid\" have been filtered out by `max_features=10000`.\n",
    "\n",
    "‚ùì Is \"cupid\" in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23de637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cupid\" in model.tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8094ac",
   "metadata": {},
   "source": [
    "üß† A difficult tradeoff between adding more features (and over-fitting) and limiting them (and missing cases like this)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece5e52",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"headline\": \"Texas Adoption Bill Could Allow Anti-Gay, Religious Discrimination\",\n",
    "    \"short_description\": \"Critics of the bill say it legitimizes discrimination with taxpayer money.\",\n",
    "    \"id\": 41233,\n",
    "    \"label_true\": \"G: US Politics\",\n",
    "    \"label_pred\": \"D: Diversity\"\n",
    "}\n",
    "```\n",
    "\n",
    "üö® We see cases that could be the predicted class, even though ground truth label says otherwise.\n",
    "\n",
    "üß† Is this problem misspecificed? Is it really a multi-label problem (but our dataset only gives a single class).\n",
    "\n",
    "üß† Would the downstream application need a single class? Or would it support multi-label?\n",
    "\n",
    "üß† Where is this model being used? Just for search? In which case multi-label might work.\n",
    "\n",
    "üö® Would clarift these requirements in a real world assignment.\n",
    "\n",
    "‚≠êÔ∏è Will focus on multi-class given time constaints, but would be interesting to map to a multi-label problem.\n",
    "\n",
    "üß† Some multi-label methods don't need complete labels to learn.\n",
    "\n",
    "‚≠êÔ∏è Would also like to generate a confusion matrix to see which classes are being confused with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02daa79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
